{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda create -n name python=3.10\n",
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    "# !conda install matplotlib numpy scipy scikit-learn jupyter\n",
    "# !conda install -c conda-forge scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import deepxde.deepxde as dde\n",
    "from deepxde.deepxde.nn.pytorch.deeponet import DeepONetCartesianProd\n",
    "\n",
    "from utils.func import *\n",
    "from utils.loss import dataLoss, pinnLoss\n",
    "from utils.op import *\n",
    "from utils.pdes import diffusion_reaction_nointep as diffusion_reaction\n",
    "from utils.logger import getLogger\n",
    "from dataset import parallel_solver\n",
    "from dataset.ADRSolver import diffusion_reaction_solver\n",
    "pde = lambda x, y: diffusion_reaction(x, y, D = 0.01, k = 0.01)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34;20mMain\u001b[0m - \u001b[49;90m13:17:16\u001b[0m - \u001b[32;20mINFO\u001b[0m: This code is a basic example of the DeepONet using physics-informed active learning.\n",
      "\u001b[34;20mMain\u001b[0m - \u001b[49;90m13:17:16\u001b[0m - \u001b[32;20mINFO\u001b[0m: Using 1 GPU(s). The name of devices: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
      "\u001b[34;20mMain\u001b[0m - \u001b[49;90m13:17:16\u001b[0m - \u001b[32;20mINFO\u001b[0m: Training hyperparameters:\n",
      "\u001b[34;20mMain\u001b[0m - \u001b[49;90m13:17:16\u001b[0m - \u001b[32;20mINFO\u001b[0m: batchsize: 1, iteration: 1000, lr = 0.001, decay_step = 200, decay_rate = 0.5, initial data: 20, testing number: 100, selecting number: 20, total data: 200.\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "testing = True      # testing the code or not\n",
    "name = \"Example\"    # name of the model\n",
    "info = \"This code is a basic example of the DeepONet using physics-informed active learning.\"\n",
    "testing_data = \"dataset/DF_1000test_ls0.1_101x101.npz\"\n",
    "\n",
    "if testing:\n",
    "    n_init = 20 # number of v(x) use to pre-train the model\n",
    "    n_0 = 100 # number of v(x) would be selected from the training data\n",
    "    n_1 = 20 # number of v(x) in n0 would be used to train the model\n",
    "    n_2 = 200 # total v(x) would be used to train the model\n",
    "\n",
    "    batchsize = 1 # batchsize for training, 5000 for testing the code. Defaults to 20000.\n",
    "    iteration = 1000 # iteration for training, 5000 for testing the code. Defaults to 30000.\n",
    "    shuf_dataset = True # shuffle the dataset or not\n",
    "\n",
    "    lr = 1e-3 # learning rate\n",
    "    decay_step = iteration // 5 # decay step, using inverse time decay \n",
    "    decay_rate = 0.5\n",
    "else:\n",
    "    n_init = 20 # number of v(x) use to pre-train the model\n",
    "    n_0 = 100 # number of v(x) would be selected from the training data\n",
    "    n_1 = 20 # number of v(x) in n0 would be used to train the model\n",
    "    n_2 = 200 # total v(x) would be used to train the model\n",
    "\n",
    "    batchsize = 1 # batchsize for training, 5000 for testing the code. Defaults to 20000.\n",
    "    iteration = 20000 # iteration for training, 5000 for testing the code. Defaults to 30000.\n",
    "    shuf_dataset = True # shuffle the dataset or not\n",
    "\n",
    "    lr = 1e-3 # learning rate\n",
    "    decay_step = iteration // 5 # decay step, using inverse time decay \n",
    "    decay_rate = 0.5\n",
    "\n",
    "dir_name = f\"{name}-{time.strftime('%m%d-%H%M%S', time.localtime())}\" if not testing else \"test\"\n",
    "os.makedirs(f\"model/{dir_name}\", exist_ok = True)\n",
    "\n",
    "logger = getLogger(f\"model/{dir_name}/train.log\")\n",
    "logger.info(info)\n",
    "logger.info(f\"Using {torch.cuda.device_count()} GPU(s). The name of devices: {torch.cuda.get_device_name()}\")\n",
    "logger.info(f\"Training hyperparameters:\")\n",
    "logger.info(f\"batchsize: {batchsize}, iteration: {iteration}, lr = {lr}, decay_step = {decay_step}, decay_rate = {decay_rate}, initial data: {n_init}, testing number: {n_0}, selecting number: {n_1}, total data: {n_2}.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network understanding\n",
    "Input function $u$ is the unknown function given by the sensor. Every sensor has a different location, so the input function can be approximated by these sensors. Let the $i$-th sensor be located at $\\bm{x_i}$. Then the input function is $u(\\bm{x_i})$.\n",
    "\n",
    "Therefore, if we have 100 sensors, we have 100 values of $u_i = u(\\bm{x_i})$. Then the Branch net would use these 100 $u_i$ as inputs and output given number of $b_i$.\n",
    "\n",
    "For the Trunk net, since we got the $\\bm{x_i}$ for every sensor, we could make use of these $\\bm{x_i}$ to train the Trunk net. The Trunk net takes $\\bm{x_i}$ as input and output $t_i$.\n",
    "\n",
    "Finally, the deepONet output is:\n",
    "$$ \\sum_i{b_it_i} + b_0. $$\n",
    "\n",
    "# Data for this problem\n",
    "The goal of us is to solve $u(x,t)$ by the following equation and given $v(x)$.\n",
    "$$ \\frac{\\partial u}{\\partial t} = D \\frac{\\partial^2 u}{\\partial x^2} + ku^2 + v(x), \\quad x,t \\in [0,1]$$\n",
    "\n",
    "Here, we sample the points $\\bm{x} = (x,t)$ uniformly in $[0,1] \\times [0,1]$. And we provide 1000 different $v(x)$, each one has 101 uniformly sampled points in $[0,1]$. For $u(x,t)$, we have 10201 uniformly sampled points in $[0,1] \\times [0,1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34;20mMain\u001b[0m - \u001b[49;90m13:17:17\u001b[0m - \u001b[32;20mINFO\u001b[0m: Training data: Random\n",
      "\u001b[34;20mMain\u001b[0m - \u001b[49;90m13:17:17\u001b[0m - \u001b[32;20mINFO\u001b[0m: vx shape (20, 101), uxt shape (20, 10201), grid shape (10201, 2).\n",
      "\u001b[34;20mMain\u001b[0m - \u001b[49;90m13:17:17\u001b[0m - \u001b[32;20mINFO\u001b[0m: Testing data: dataset/DF_1000test_ls0.1_101x101.npz.\n",
      "\u001b[34;20mMain\u001b[0m - \u001b[49;90m13:17:17\u001b[0m - \u001b[32;20mINFO\u001b[0m: vx shape (100, 101), uxt shape (100, 10201), grid shape (10201, 2).\n"
     ]
    }
   ],
   "source": [
    "space = dde.data.GRF(1.0, length_scale = 0.1, N= 1000, interp=\"cubic\")\n",
    "vxs = space.eval_batch(space.random(20), np.linspace(0, 1, 101)[:, None])\n",
    "uxts = parallel_solver(diffusion_reaction_solver, vxs)\n",
    "uxts, grid = np.asarray([utx[1] for utx in uxts]), uxts[0][0]\n",
    "\n",
    "train_vxs = vxs.astype(np.float32)\n",
    "train_uxts = uxts.reshape(uxts.shape[0], -1).astype(np.float32)\n",
    "train_grid = grid.reshape(-1, grid.shape[-1]).astype(np.float32)\n",
    "logger.info(f\"Training data: Random\")\n",
    "logger.info(f\"vx shape {train_vxs.shape}, uxt shape {train_uxts.shape}, grid shape {train_grid.shape}.\")\n",
    "\n",
    "test_data = np.load(testing_data)\n",
    "vxs, uxts, grid = test_data[\"vxs\"], test_data[\"uxts\"], test_data[\"xt\"]\n",
    "\n",
    "test_vxs = vxs.astype(np.float32)[:100]\n",
    "test_uxts = uxts.reshape(uxts.shape[0], -1).astype(np.float32)[:100]\n",
    "test_grid = grid.reshape(-1, grid.shape[-1]).astype(np.float32)\n",
    "logger.info(f\"Testing data: {testing_data}.\")\n",
    "logger.info(f\"vx shape {test_vxs.shape}, uxt shape {test_uxts.shape}, grid shape {test_grid.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.000386 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = PDETripleCartesianProd(X_train=(train_vxs, train_grid), y_train=train_uxts, X_test=(test_vxs, test_grid), y_test=test_uxts)\n",
    "\n",
    "net = DeepONetCartesianProd(\n",
    "        layer_sizes_branch= [101, 100, 100],\n",
    "        layer_sizes_trunk= [2, 100, 100, 100],\n",
    "        activation= {\"branch\": F.gelu, \"trunk\": F.gelu},\n",
    "        kernel_initializer= \"Glorot normal\")\n",
    "\n",
    "net.apply_output_transform(dirichlet)\n",
    "\n",
    "checker = dde.callbacks.ModelCheckpoint(f\"model/{dir_name}/{name}_\", save_better_only=False, period=10000)\n",
    "\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", loss = [dataLoss(), ], lr=lr, metrics=[], decay = (torch.optim.lr_scheduler.LambdaLR, [], {\"lr_lambda\": lambda step: 1 / (1 + decay_rate * (step / decay_step))}))\n",
    "#pinnLoss(diffusion_reaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "0         [6.02e-01]    [3.28e-01]    []  \n",
      "5000      [5.54e-02]    [7.13e-02]    []  \n",
      "10000     [8.26e-03]    [6.03e-02]    []  \n",
      "15000     [1.73e-02]    [6.02e-02]    []  \n",
      "20000     [5.70e-03]    [6.10e-02]    []  \n",
      "\n",
      "Best model at step 20000:\n",
      "  train loss: 5.70e-03\n",
      "  test loss: 6.10e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 162.697684 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First train without any techniques\n",
    "loss_history, train_state = model.train(iterations = 20000,\n",
    "                                        callbacks = [checker],\n",
    "                                        batch_size = batchsize,\n",
    "                                        test_batch_size = 10,\n",
    "                                        display_every = 5000,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_vxs(model, vx_number: int = 10, grid: np.ndarray = grid):\n",
    "    space = dde.data.GRF(1.0, length_scale = 0.1, N= 1000, interp=\"cubic\")\n",
    "    vxs = space.eval_batch(space.random(10), np.linspace(0, 1, 101)[:, None])\n",
    "    vxs = torch.from_numpy(vxs)\n",
    "    grid = torch.from_numpy(grid)\n",
    "    results = model.predict((vxs, grid), pinnLoss(diffusion_reaction, func = lambda x, y: (x -y).abs()))\n",
    "    return vxs, torch.from_numpy(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.001362 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [4.65e-03]    [6.10e-02]    []  \n",
      "5000      [1.88e-03]    [3.68e-02]    []  \n",
      "10000     [8.52e-03]    [3.87e-02]    []  \n",
      "15000     [6.65e-03]    [3.84e-02]    []  \n",
      "20000     [1.66e-03]    [3.85e-02]    []  \n",
      "\n",
      "Best model at step 20000:\n",
      "  train loss: 1.66e-03\n",
      "  test loss: 3.85e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 142.073638 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000603 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [7.27e-03]    [3.85e-02]    []  \n",
      "5000      [1.06e-02]    [2.04e-02]    []  \n",
      "10000     [2.67e-03]    [1.92e-02]    []  \n",
      "15000     [5.81e-03]    [1.89e-02]    []  \n",
      "20000     [4.72e-03]    [1.87e-02]    []  \n",
      "\n",
      "Best model at step 10000:\n",
      "  train loss: 2.67e-03\n",
      "  test loss: 1.92e-02\n",
      "  test metric: []\n",
      "\n",
      "'train' took 149.845083 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000619 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [4.67e-02]    [1.87e-02]    []  \n",
      "5000      [2.51e-03]    [1.05e-02]    []  \n",
      "10000     [1.56e-03]    [9.84e-03]    []  \n",
      "15000     [2.05e-04]    [9.58e-03]    []  \n",
      "20000     [5.10e-04]    [9.51e-03]    []  \n",
      "\n",
      "Best model at step 15000:\n",
      "  train loss: 2.05e-04\n",
      "  test loss: 9.58e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 151.392058 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000611 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [5.24e-04]    [9.51e-03]    []  \n",
      "5000      [8.45e-04]    [6.39e-03]    []  \n",
      "10000     [1.51e-03]    [5.70e-03]    []  \n",
      "15000     [6.07e-04]    [5.54e-03]    []  \n",
      "20000     [8.10e-04]    [5.52e-03]    []  \n",
      "\n",
      "Best model at step 0:\n",
      "  train loss: 5.24e-04\n",
      "  test loss: 9.51e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 144.415968 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000680 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [1.10e-03]    [5.52e-03]    []  \n",
      "5000      [3.56e-03]    [4.57e-03]    []  \n",
      "10000     [2.14e-03]    [4.07e-03]    []  \n",
      "15000     [8.95e-04]    [4.01e-03]    []  \n",
      "20000     [2.63e-03]    [3.96e-03]    []  \n",
      "\n",
      "Best model at step 15000:\n",
      "  train loss: 8.95e-04\n",
      "  test loss: 4.01e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 149.114897 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000525 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [1.02e-03]    [3.96e-03]    []  \n",
      "5000      [1.77e-03]    [3.33e-03]    []  \n",
      "10000     [4.32e-03]    [3.30e-03]    []  \n",
      "15000     [3.81e-03]    [3.22e-03]    []  \n",
      "20000     [6.89e-04]    [3.16e-03]    []  \n",
      "\n",
      "Best model at step 20000:\n",
      "  train loss: 6.89e-04\n",
      "  test loss: 3.16e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 148.062373 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000534 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [9.02e-04]    [3.16e-03]    []  \n",
      "5000      [6.91e-04]    [3.05e-03]    []  \n",
      "10000     [1.47e-03]    [2.79e-03]    []  \n",
      "15000     [7.80e-04]    [2.65e-03]    []  \n",
      "20000     [3.85e-03]    [2.64e-03]    []  \n",
      "\n",
      "Best model at step 5000:\n",
      "  train loss: 6.91e-04\n",
      "  test loss: 3.05e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 137.010564 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000542 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [4.51e-04]    [2.64e-03]    []  \n",
      "5000      [1.25e-03]    [2.35e-03]    []  \n",
      "10000     [1.29e-03]    [2.20e-03]    []  \n",
      "15000     [2.61e-04]    [2.15e-03]    []  \n",
      "20000     [1.43e-03]    [2.08e-03]    []  \n",
      "\n",
      "Best model at step 15000:\n",
      "  train loss: 2.61e-04\n",
      "  test loss: 2.15e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 108.902434 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000553 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric\n",
      "0         [4.99e-04]    [2.08e-03]    []  \n",
      "5000      [2.35e-03]    [1.81e-03]    []  \n",
      "10000     [6.20e-04]    [1.67e-03]    []  \n",
      "15000     [2.44e-04]    [1.59e-03]    []  \n",
      "20000     [1.02e-03]    [1.56e-03]    []  \n",
      "\n",
      "Best model at step 15000:\n",
      "  train loss: 2.44e-04\n",
      "  test loss: 1.59e-03\n",
      "  test metric: []\n",
      "\n",
      "'train' took 110.017385 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while len(train_vxs) < n_2:\n",
    "    vxs, results = [], []\n",
    "    for i in range(n_0 // 10):\n",
    "        vx, result = test_new_vxs(model, vx_number=10, grid=train_grid)\n",
    "        vxs.append(vx)\n",
    "        results.append(result)\n",
    "    vxs = torch.cat(vxs)\n",
    "    results = torch.cat(results)\n",
    "    results = results.mean(axis=1)[..., 0]\n",
    "    indices = torch.topk(results, n_1)[1]\n",
    "    vxs = vxs[indices]\n",
    "    vxs = vxs.numpy()\n",
    "    uxts = parallel_solver(diffusion_reaction_solver, vxs)\n",
    "    uxts, grid = np.asarray([utx[1] for utx in uxts]), uxts[0][0]\n",
    "\n",
    "    train_vxs = np.concatenate([train_vxs, vxs], 0).astype(np.float32)\n",
    "    train_uxts = np.concatenate(\n",
    "        [train_uxts, uxts.reshape(uxts.shape[0], -1)], 0).astype(np.float32)\n",
    "\n",
    "    data = PDETripleCartesianProd(X_train=(train_vxs, train_grid), y_train=train_uxts, X_test=(\n",
    "        test_vxs, test_grid), y_test=test_uxts)\n",
    "\n",
    "    model = dde.Model(data, net)\n",
    "    model.compile(\"adam\", loss=[dataLoss(),], lr=lr, metrics=[], decay=(torch.optim.lr_scheduler.LambdaLR, [\n",
    "    ], {\"lr_lambda\": lambda step: 1 / (1 + decay_rate * (step / decay_step))}))\n",
    "    # pinnLoss(diffusion_reaction)\n",
    "    loss_history, train_state = model.train(iterations=20000,\n",
    "                                            callbacks=[checker],\n",
    "                                            batch_size=batchsize,\n",
    "                                            test_batch_size=10,\n",
    "                                            display_every=5000,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dde.data.Triple(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", lr=lr)\n",
    "model.restore(\"model/model0.ckpt-23000.pt\", verbose=1)\n",
    "\n",
    "index = 1\n",
    "\n",
    "v_x = test_data[\"X_test0\"][index] # 101\n",
    "u_gt = test_data[\"y_test\"][index]\n",
    "\n",
    "X = test_data[\"X_test1\"] # 10201, 2\n",
    "\n",
    "sensor_value = v_x[None, :].repeat(10201, axis=0) # 10201, 101\n",
    "\n",
    "u_pd = model.predict((sensor_value, X))[:,0] # 10201, 1\n",
    "fig, (ax1, ax2,ax3) = plt.subplots(1, 3)\n",
    "fig.suptitle(\"$u(x,t)$\")\n",
    "fig.set_size_inches(4 * 3,  4)\n",
    "ax1.set_title(f\"{index}_gt\")\n",
    "ax1.set_xlim([0, 1])\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_aspect('equal')\n",
    "ax1.set_xlabel(\"$x$\")\n",
    "ax1.set_ylabel(\"$t$\")\n",
    "scatter = ax1.scatter(X[:,0], X[:, 1], c=u_gt)\n",
    "colorbar = plt.colorbar(scatter, ax = ax1, shrink=0.7)\n",
    "\n",
    "ax2.set_title(f\"{index}_pd\")\n",
    "ax2.set_xlim([0, 1])\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlabel(\"$x$\")\n",
    "ax2.set_ylabel(\"$t$\")\n",
    "scatter = ax2.scatter(X[:,0], X[:, 1], c=u_pd)\n",
    "colorbar = plt.colorbar(scatter, ax = ax2, shrink=0.7)\n",
    "\n",
    "ax3.set_title(f\"{index}_delta\")\n",
    "ax3.set_xlim([0, 1])\n",
    "ax3.set_ylim([0, 1])\n",
    "ax3.set_aspect('equal')\n",
    "ax3.set_xlabel(\"$x$\")\n",
    "ax3.set_ylabel(\"$t$\")\n",
    "scatter = ax3.scatter(X[:,0], X[:, 1], c=u_pd - u_gt)\n",
    "colorbar = plt.colorbar(scatter, ax = ax3, shrink=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
